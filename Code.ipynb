{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deciphering Infant Distress:** *Unveiling the Hidden Patterns Behind Baby Cries Using Machine Learning Techniques*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1:** Let's train a ML model and test it's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by collecting all of the sample audio files we have, splitting them into smaller audio snippets and training a collection of machine learning algorithms with one part of this data.  With another part of the data we will test and see how well the algorithms predict data they have never seen before and then choose the best algorithm for our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1:**  Grab the audio file and its label (we have 9 labels: belly_pain, cold_hot, discomfort, hungry, lonely, need_to_burp, scared, tired, unknown)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:50:06.136605Z",
     "start_time": "2024-08-26T12:50:06.119324Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# Store all audio files in a dictionary where key: filename, value: label\n",
    "raw_audio = {}\n",
    "\n",
    "# Define directories for each label\n",
    "directories = {\n",
    "    'belly_pain_folder': 'bp',\n",
    "    'cold_hot_folder': 'ch',\n",
    "    'discomfort_folder': 'dc',\n",
    "    'hungry_folder': 'hu',\n",
    "    'lonely_folder': 'lo',\n",
    "    'need_to_burp_folder': 'bu',\n",
    "    'scared_folder': 'sc',\n",
    "    'tired_folder': 'ti',\n",
    "    'unknown_folder': 'un',\n",
    "}\n",
    "\n",
    "# Path to the Training_Dataset folder\n",
    "dataset_folder = \"dataset\"\n",
    "\n",
    "# Iterate through each directory\n",
    "for directory, label in directories.items():\n",
    "    # Path to the current label folder\n",
    "    label_directory = os.path.join(dataset_folder, directory)\n",
    "    # Iterate through files in the directory\n",
    "    for filename in os.listdir(label_directory):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            # Add file path and label to the dictionary\n",
    "            raw_audio[os.path.join(label_directory, filename)] = label\n",
    "\n",
    "# Print the dictionary containing file paths and labels\n",
    "# print(raw_audio)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2:**  Split the audio files into 1 second snippets and save them in corresponding folders of their label names"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:50:12.763200Z",
     "start_time": "2024-08-26T12:50:11.136987Z"
    }
   },
   "source": [
    "import wave \n",
    "import math\n",
    "import os\n",
    "\n",
    "def split_audio(filename, folder):\n",
    "    # Open the audio file\n",
    "    handle = wave.open(filename, 'rb')\n",
    "    frame_rate = handle.getframerate() # Frame rate\n",
    "    n_frames = handle.getnframes() # Total number of frames\n",
    "    window_size = frame_rate  # Set window size with no. of frames generated in 1 second\n",
    "    num_secs = int(math.ceil(n_frames / frame_rate)) # Total number of seconds in the audio file\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = f'splitted_audio/{folder}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Slicing Audio file\n",
    "    for i in range(num_secs):\n",
    "        # Generate snippet filename\n",
    "        shortfilename = os.path.basename(filename).split(\".\")[0]\n",
    "        snippetfilename = f'{output_dir}/{shortfilename}_snippet{i+1}.wav'\n",
    "        # print(snippetfilename)\n",
    "        \n",
    "        # Open snippet file for writing\n",
    "        with wave.open(snippetfilename, 'wb') as snippet:\n",
    "            snippet.setnchannels(handle.getnchannels()) # number of independent audio signals within the audio file\n",
    "            # print(handle.getnchannels())\n",
    "            snippet.setsampwidth(handle.getsampwidth()) # number of bytes used to represent each audio sample\n",
    "            # print(handle.getsampwidth())\n",
    "            snippet.setframerate(frame_rate)\n",
    "            \n",
    "            # Write frames for 1-second snippet\n",
    "            snippet.writeframes(handle.readframes(window_size))\n",
    "            \n",
    "    handle.close()\n",
    "\n",
    "# Iterate through each audio file in raw_audio dictionary\n",
    "for audio_file, label in raw_audio.items():\n",
    "    split_audio(audio_file, label)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3:**  Transform .wav files to frequency spectrum \"fingerprints\" using MFCC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:51:32.242905Z",
     "start_time": "2024-08-26T12:50:25.121739Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import librosa \n",
    "import numpy as np\n",
    "'''Split and Transform each track'''\n",
    "X = pd.DataFrame(columns = np.arange(45), dtype = 'float32').astype(np.float32)\n",
    "j = 0\n",
    "k = 0\n",
    "l = 0\n",
    "m = 0\n",
    "n = 0\n",
    "o = 0\n",
    "p = 0\n",
    "q = 0\n",
    "\n",
    "for i, filename in enumerate(os.listdir('splitted_audio/bp/')):\n",
    "    last_number_frames = -1\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"splitted_audio/bp/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'bp'\n",
    "        X.loc[i] = x.loc[0]\n",
    "        j = i\n",
    "        \n",
    "for i, filename in enumerate(os.listdir('splitted_audio/bu/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"splitted_audio/bu/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'bu'\n",
    "        X.loc[i+j] = x.loc[0] \n",
    "        k = i \n",
    "        \n",
    "for i, filename in enumerate(os.listdir('splitted_audio/ch/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"splitted_audio/ch/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'ch'\n",
    "        X.loc[i+j+k] = x.loc[0]\n",
    "        l = i\n",
    "        \n",
    "for i, filename in enumerate(os.listdir('splitted_audio/dc/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"splitted_audio/dc/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'dc'\n",
    "        X.loc[i+j+k+l] = x.loc[0]\n",
    "        m = i\n",
    "        \n",
    "for i, filename in enumerate(os.listdir('splitted_audio/hu/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"splitted_audio/hu/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'hu'\n",
    "        X.loc[i+j+k+l+m] = x.loc[0]\n",
    "        n = i\n",
    "        \n",
    "for i, filename in enumerate(os.listdir('splitted_audio/lo/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"splitted_audio/lo/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'lo'\n",
    "        X.loc[i+j+k+l+m+n] = x.loc[0]\n",
    "        o = i\n",
    "        \n",
    "for i, filename in enumerate(os.listdir('splitted_audio/sc/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"splitted_audio/sc/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'sc'\n",
    "        X.loc[i+j+k+l+m+n+o] = x.loc[0]\n",
    "        p = i\n",
    "        \n",
    "for i, filename in enumerate(os.listdir('splitted_audio/ti/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"splitted_audio/ti/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'ti'\n",
    "        X.loc[i+j+k+l+m+n+o+p] = x.loc[0]\n",
    "        q = i\n",
    "        \n",
    "for i, filename in enumerate(os.listdir('splitted_audio/un/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"splitted_audio/un/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'un'\n",
    "        X.loc[i+j+k+l+m+n+o+p+q] = x.loc[0]\n",
    "        \n",
    "        \n",
    "#Do something with missing values. you might want to do something more sophisticated with missing values later\n",
    "X = X.fillna(0)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=441\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=441\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:51:32.307118Z",
     "start_time": "2024-08-26T12:51:32.246243Z"
    }
   },
   "source": [
    "# With each row representing an audio sample and each column representing a feature. (last column represents label)\n",
    "X.head(100)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            0           1           2           3           4           5   \\\n",
       "0  -886.068054 -886.068054 -886.068054 -886.068054 -886.068054 -886.068054   \n",
       "1  -751.045105 -729.236511 -708.148621 -693.773499 -670.862305 -624.201660   \n",
       "2  -772.133057 -744.162903 -741.084167 -741.149719 -732.525146 -725.661926   \n",
       "3  -486.896667 -504.154694 -528.663208 -498.589417 -473.853363 -465.715942   \n",
       "4  -489.437866 -469.426788 -466.268738 -480.051727 -509.546631 -514.609497   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "95 -321.022552 -354.151215 -404.709534 -404.258514 -387.059204 -364.865204   \n",
       "96 -503.402191 -441.360291 -417.368317 -392.223663 -368.167297 -347.077240   \n",
       "97 -307.596680 -326.190186 -326.334900 -297.229584 -289.203918 -287.868042   \n",
       "98 -256.617462 -265.644867 -331.424805 -320.991882 -303.306793 -310.959351   \n",
       "99 -268.247528 -283.085205 -294.851349 -268.481812 -255.947464 -259.890839   \n",
       "\n",
       "            6           7           8           9   ...          35  \\\n",
       "0  -886.068054 -886.068054 -886.068054 -886.068054  ... -658.678040   \n",
       "1  -610.616272 -610.707886 -620.584717 -650.334167  ... -785.789490   \n",
       "2  -725.300781 -726.574707 -738.909912 -756.122864  ... -738.214294   \n",
       "3  -491.972198 -515.916199 -522.104370 -507.522522  ... -513.860657   \n",
       "4  -500.760651 -492.276031 -497.030273 -489.642792  ... -353.614197   \n",
       "..         ...         ...         ...         ...  ...         ...   \n",
       "95 -373.956757 -402.979828 -411.734528 -412.828400  ... -480.670410   \n",
       "96 -330.584229 -330.370209 -333.220734 -323.803772  ... -501.077423   \n",
       "97 -297.142151 -307.698792 -319.570282 -331.128052  ... -295.481781   \n",
       "98 -313.470551 -316.066620 -323.012482 -326.000641  ... -373.191742   \n",
       "99 -261.366302 -255.894485 -261.457184 -257.035156  ... -543.683044   \n",
       "\n",
       "            36          37          38          39          40          41  \\\n",
       "0  -639.897400 -588.136902 -586.255798 -610.009155 -610.174255 -635.943604   \n",
       "1  -775.371216 -767.533813 -774.619324 -776.557129 -774.774963 -771.559326   \n",
       "2  -714.469360 -688.410828 -644.362305 -595.480042 -571.091003 -550.012207   \n",
       "3  -504.099640 -507.292999 -541.001099 -554.377930 -553.175903 -563.970520   \n",
       "4  -355.154236 -356.105713 -360.017853 -348.864044 -338.575378 -336.447205   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "95 -476.497864 -472.598938 -469.486816    0.000000    0.000000    0.000000   \n",
       "96 -517.778564 -507.529175 -439.600769 -369.505768 -325.605652 -316.413208   \n",
       "97 -304.866028 -338.403595 -383.328247 -427.990601 -435.038025 -362.225037   \n",
       "98 -372.921906 -385.820862 -388.424042 -379.771332 -375.435425 -366.014343   \n",
       "99 -550.093445 -567.024170 -574.153442 -578.357849 -584.517944 -584.888184   \n",
       "\n",
       "            42          43  44  \n",
       "0  -703.638977 -732.864746  bp  \n",
       "1  -772.556458 -794.632568  bp  \n",
       "2  -497.703308 -478.067719  bp  \n",
       "3  -528.158081 -509.625885  bp  \n",
       "4  -293.900269 -282.138824  bp  \n",
       "..         ...         ...  ..  \n",
       "95    0.000000    0.000000  ch  \n",
       "96 -291.361816 -279.147583  ch  \n",
       "97 -246.358459 -227.138657  ch  \n",
       "98 -291.503204 -253.155869  ch  \n",
       "99 -582.082825 -596.394043  ch  \n",
       "\n",
       "[100 rows x 45 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-886.068054</td>\n",
       "      <td>-886.068054</td>\n",
       "      <td>-886.068054</td>\n",
       "      <td>-886.068054</td>\n",
       "      <td>-886.068054</td>\n",
       "      <td>-886.068054</td>\n",
       "      <td>-886.068054</td>\n",
       "      <td>-886.068054</td>\n",
       "      <td>-886.068054</td>\n",
       "      <td>-886.068054</td>\n",
       "      <td>...</td>\n",
       "      <td>-658.678040</td>\n",
       "      <td>-639.897400</td>\n",
       "      <td>-588.136902</td>\n",
       "      <td>-586.255798</td>\n",
       "      <td>-610.009155</td>\n",
       "      <td>-610.174255</td>\n",
       "      <td>-635.943604</td>\n",
       "      <td>-703.638977</td>\n",
       "      <td>-732.864746</td>\n",
       "      <td>bp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-751.045105</td>\n",
       "      <td>-729.236511</td>\n",
       "      <td>-708.148621</td>\n",
       "      <td>-693.773499</td>\n",
       "      <td>-670.862305</td>\n",
       "      <td>-624.201660</td>\n",
       "      <td>-610.616272</td>\n",
       "      <td>-610.707886</td>\n",
       "      <td>-620.584717</td>\n",
       "      <td>-650.334167</td>\n",
       "      <td>...</td>\n",
       "      <td>-785.789490</td>\n",
       "      <td>-775.371216</td>\n",
       "      <td>-767.533813</td>\n",
       "      <td>-774.619324</td>\n",
       "      <td>-776.557129</td>\n",
       "      <td>-774.774963</td>\n",
       "      <td>-771.559326</td>\n",
       "      <td>-772.556458</td>\n",
       "      <td>-794.632568</td>\n",
       "      <td>bp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-772.133057</td>\n",
       "      <td>-744.162903</td>\n",
       "      <td>-741.084167</td>\n",
       "      <td>-741.149719</td>\n",
       "      <td>-732.525146</td>\n",
       "      <td>-725.661926</td>\n",
       "      <td>-725.300781</td>\n",
       "      <td>-726.574707</td>\n",
       "      <td>-738.909912</td>\n",
       "      <td>-756.122864</td>\n",
       "      <td>...</td>\n",
       "      <td>-738.214294</td>\n",
       "      <td>-714.469360</td>\n",
       "      <td>-688.410828</td>\n",
       "      <td>-644.362305</td>\n",
       "      <td>-595.480042</td>\n",
       "      <td>-571.091003</td>\n",
       "      <td>-550.012207</td>\n",
       "      <td>-497.703308</td>\n",
       "      <td>-478.067719</td>\n",
       "      <td>bp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-486.896667</td>\n",
       "      <td>-504.154694</td>\n",
       "      <td>-528.663208</td>\n",
       "      <td>-498.589417</td>\n",
       "      <td>-473.853363</td>\n",
       "      <td>-465.715942</td>\n",
       "      <td>-491.972198</td>\n",
       "      <td>-515.916199</td>\n",
       "      <td>-522.104370</td>\n",
       "      <td>-507.522522</td>\n",
       "      <td>...</td>\n",
       "      <td>-513.860657</td>\n",
       "      <td>-504.099640</td>\n",
       "      <td>-507.292999</td>\n",
       "      <td>-541.001099</td>\n",
       "      <td>-554.377930</td>\n",
       "      <td>-553.175903</td>\n",
       "      <td>-563.970520</td>\n",
       "      <td>-528.158081</td>\n",
       "      <td>-509.625885</td>\n",
       "      <td>bp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-489.437866</td>\n",
       "      <td>-469.426788</td>\n",
       "      <td>-466.268738</td>\n",
       "      <td>-480.051727</td>\n",
       "      <td>-509.546631</td>\n",
       "      <td>-514.609497</td>\n",
       "      <td>-500.760651</td>\n",
       "      <td>-492.276031</td>\n",
       "      <td>-497.030273</td>\n",
       "      <td>-489.642792</td>\n",
       "      <td>...</td>\n",
       "      <td>-353.614197</td>\n",
       "      <td>-355.154236</td>\n",
       "      <td>-356.105713</td>\n",
       "      <td>-360.017853</td>\n",
       "      <td>-348.864044</td>\n",
       "      <td>-338.575378</td>\n",
       "      <td>-336.447205</td>\n",
       "      <td>-293.900269</td>\n",
       "      <td>-282.138824</td>\n",
       "      <td>bp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-321.022552</td>\n",
       "      <td>-354.151215</td>\n",
       "      <td>-404.709534</td>\n",
       "      <td>-404.258514</td>\n",
       "      <td>-387.059204</td>\n",
       "      <td>-364.865204</td>\n",
       "      <td>-373.956757</td>\n",
       "      <td>-402.979828</td>\n",
       "      <td>-411.734528</td>\n",
       "      <td>-412.828400</td>\n",
       "      <td>...</td>\n",
       "      <td>-480.670410</td>\n",
       "      <td>-476.497864</td>\n",
       "      <td>-472.598938</td>\n",
       "      <td>-469.486816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-503.402191</td>\n",
       "      <td>-441.360291</td>\n",
       "      <td>-417.368317</td>\n",
       "      <td>-392.223663</td>\n",
       "      <td>-368.167297</td>\n",
       "      <td>-347.077240</td>\n",
       "      <td>-330.584229</td>\n",
       "      <td>-330.370209</td>\n",
       "      <td>-333.220734</td>\n",
       "      <td>-323.803772</td>\n",
       "      <td>...</td>\n",
       "      <td>-501.077423</td>\n",
       "      <td>-517.778564</td>\n",
       "      <td>-507.529175</td>\n",
       "      <td>-439.600769</td>\n",
       "      <td>-369.505768</td>\n",
       "      <td>-325.605652</td>\n",
       "      <td>-316.413208</td>\n",
       "      <td>-291.361816</td>\n",
       "      <td>-279.147583</td>\n",
       "      <td>ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-307.596680</td>\n",
       "      <td>-326.190186</td>\n",
       "      <td>-326.334900</td>\n",
       "      <td>-297.229584</td>\n",
       "      <td>-289.203918</td>\n",
       "      <td>-287.868042</td>\n",
       "      <td>-297.142151</td>\n",
       "      <td>-307.698792</td>\n",
       "      <td>-319.570282</td>\n",
       "      <td>-331.128052</td>\n",
       "      <td>...</td>\n",
       "      <td>-295.481781</td>\n",
       "      <td>-304.866028</td>\n",
       "      <td>-338.403595</td>\n",
       "      <td>-383.328247</td>\n",
       "      <td>-427.990601</td>\n",
       "      <td>-435.038025</td>\n",
       "      <td>-362.225037</td>\n",
       "      <td>-246.358459</td>\n",
       "      <td>-227.138657</td>\n",
       "      <td>ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-256.617462</td>\n",
       "      <td>-265.644867</td>\n",
       "      <td>-331.424805</td>\n",
       "      <td>-320.991882</td>\n",
       "      <td>-303.306793</td>\n",
       "      <td>-310.959351</td>\n",
       "      <td>-313.470551</td>\n",
       "      <td>-316.066620</td>\n",
       "      <td>-323.012482</td>\n",
       "      <td>-326.000641</td>\n",
       "      <td>...</td>\n",
       "      <td>-373.191742</td>\n",
       "      <td>-372.921906</td>\n",
       "      <td>-385.820862</td>\n",
       "      <td>-388.424042</td>\n",
       "      <td>-379.771332</td>\n",
       "      <td>-375.435425</td>\n",
       "      <td>-366.014343</td>\n",
       "      <td>-291.503204</td>\n",
       "      <td>-253.155869</td>\n",
       "      <td>ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-268.247528</td>\n",
       "      <td>-283.085205</td>\n",
       "      <td>-294.851349</td>\n",
       "      <td>-268.481812</td>\n",
       "      <td>-255.947464</td>\n",
       "      <td>-259.890839</td>\n",
       "      <td>-261.366302</td>\n",
       "      <td>-255.894485</td>\n",
       "      <td>-261.457184</td>\n",
       "      <td>-257.035156</td>\n",
       "      <td>...</td>\n",
       "      <td>-543.683044</td>\n",
       "      <td>-550.093445</td>\n",
       "      <td>-567.024170</td>\n",
       "      <td>-574.153442</td>\n",
       "      <td>-578.357849</td>\n",
       "      <td>-584.517944</td>\n",
       "      <td>-584.888184</td>\n",
       "      <td>-582.082825</td>\n",
       "      <td>-596.394043</td>\n",
       "      <td>ch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 45 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4:**  Make a Test-Train-Split of the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:51:53.746892Z",
     "start_time": "2024-08-26T12:51:53.627552Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = X[44]\n",
    "del X[44]\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# 75% of the data is allocated to the training set (X_train and y_train) and 25% to the testing set (X_test and y_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5:**  Fit the training data to a model & Check the models performance against the test data¶"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:51:57.947513Z",
     "start_time": "2024-08-26T12:51:55.948663Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "def get_scores(classifier, X_train, X_test, y_train, y_test, **kwargs):\n",
    "    model = classifier(**kwargs)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    precision = precision_score(y_test, y_predict, average='weighted', labels=np.unique(y_predict))\n",
    "    return accuracy, precision\n",
    "\n",
    "\n",
    "print(\"    Model: (Accuracy, Precision)\")\n",
    "print(\"    Random Forest:\", get_scores(RandomForestClassifier, X_train, X_test, y_train, y_test, n_estimators=25, max_features=5))\n",
    "print(\"    Logistic Regression:\", get_scores(LogisticRegression, X_train, X_test, y_train, y_test))\n",
    "print(\"    Decision Tree:\", get_scores(DecisionTreeClassifier, X_train, X_test, y_train, y_test))\n",
    "print(\"    SVM:\", get_scores(SVC, X_train, X_test, y_train, y_test))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model: (Accuracy, Precision)\n",
      "    Random Forest: (0.6214285714285714, 0.4981481543454463)\n",
      "    Logistic Regression: (0.61, 0.4706102405114259)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tusha\\anaconda3\\envs\\Ml_projects\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Decision Tree: (0.4714285714285714, 0.49290245041678643)\n",
      "    SVM: (0.6371428571428571, 0.7313913088940537)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 6:** After we are satisfied with the results of our model, we save the model into a .pkl file that we can quickly use to make predictions of new data.  I will fit a new SVM model that uses all of the data I have and save it as 'mySVM.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:52:36.684755Z",
     "start_time": "2024-08-26T12:52:35.984218Z"
    }
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def pickle_model(model, modelname):\n",
    "    # Create the \"models\" directory if it doesn't exist\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    \n",
    "    # Save the model to a .pkl file\n",
    "    with open(f'models/{modelname}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "# Assuming you have already trained your SVC model and have X, y data\n",
    "# Initialize and train your SVM model\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X, y)\n",
    "\n",
    "# Save the trained model\n",
    "pickle_model(model_svm, \"mySVM\")\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2**\n",
    "## Let's see if it works! Making Actual Predictions on new sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1:** Load the model from disk into Python"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:52:48.443537Z",
     "start_time": "2024-08-26T12:52:48.417491Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "def getModel(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "model = getModel(\"models/mySVM.pkl\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2:**  Split the .wav file and store it in a folder "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:52:55.220604Z",
     "start_time": "2024-08-26T12:52:53.034939Z"
    }
   },
   "source": [
    "import soundfile as sf\n",
    "import os\n",
    "import math\n",
    "\n",
    "def chop_new_audio(filename, folder):\n",
    "    try:\n",
    "        # Open the input audio file using soundfile\n",
    "        audio, samplerate = sf.read(filename)\n",
    "        \n",
    "        # Calculate window size for 1 second\n",
    "        window_size = samplerate\n",
    "        \n",
    "        # Calculate number of snippets\n",
    "        num_snippets = len(audio) // window_size\n",
    "        \n",
    "        # Create the output directory if it doesn't exist\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        \n",
    "        # Slicing audio file into 1-second snippets\n",
    "        for i in range(num_snippets):\n",
    "            snippetfilename = f'{folder}/{os.path.basename(filename)}_snippet{i+1}.wav'\n",
    "            \n",
    "            # Calculate start and end index for the snippet\n",
    "            start_idx = i * window_size\n",
    "            end_idx = (i + 1) * window_size\n",
    "            \n",
    "            # Write the snippet to a new wave file\n",
    "            sf.write(snippetfilename, audio[start_idx:end_idx], samplerate)\n",
    "        \n",
    "        print(\"Audio file splitted successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while splitting audio: {e}\")\n",
    "\n",
    "# Example usage\n",
    "chop_new_audio(\"babycryingformilk.wav\", \"babycryingformilk_snippets\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file splitted successfully.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3:**  Transform the splitted snippets into MFCC fingerprints and make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T12:52:59.534702Z",
     "start_time": "2024-08-26T12:52:59.128863Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "predictions = []\n",
    "# Correct the directory path to 'babycryingformilk_snippets/'\n",
    "for i, filename in enumerate(os.listdir('babycryingformilk_snippets/')):\n",
    "    last_number_frames = -1\n",
    "    if filename.endswith(\".wav\"):\n",
    "        audiofile, sr = librosa.load(\"babycryingformilk_snippets/\"+filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype='float32')\n",
    "        prediction = model.predict(x)  # Pass features 'x' to the predict method\n",
    "        predictions.append(prediction[0])\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4:** Take the mode of the predictions to come up with a final predition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-26T12:53:02.065861Z",
     "start_time": "2024-08-26T12:53:02.048090Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "\n",
    "data = Counter(predictions)\n",
    "print(data.most_common())   # Returns all unique items and their counts\n",
    "print(data.most_common(1))\n",
    "\n",
    "if data.most_common(1)[0][0] == 'bp':\n",
    "    print(\"The baby is crying because he/she is likely to be feeling belly pain.\")\n",
    "if data.most_common(1)[0][0] == 'ch':\n",
    "    print(\"The baby is crying because he/she is likely to be feeling cold or hot.\")\n",
    "if data.most_common(1)[0][0] == 'dc':\n",
    "    print(\"The baby is crying because he/she is likely to be feeling discomfort.\")\n",
    "if data.most_common(1)[0][0] == 'hu':\n",
    "    print(\"The baby is crying because he/she is likely to be hungry.\")\n",
    "if data.most_common(1)[0][0] == 'lo':\n",
    "    print(\"The baby is crying because he/she is likely to be feeling lonely.\")\n",
    "if data.most_common(1)[0][0] == 'bu':\n",
    "    print(\"The baby is crying because he/she likely to be needs to burp.\")\n",
    "if data.most_common(1)[0][0] == 'sc':\n",
    "    print(\"The baby is crying because he/she is likely to be scared.\")\n",
    "if data.most_common(1)[0][0] == 'ti':\n",
    "    print(\"The baby is crying because he/she is likely to be tired.\")\n",
    "if data.most_common(1)[0][0] == 'un':\n",
    "    print(\"The reason why the baby is crying is unknown.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hu', 29)]\n",
      "[('hu', 29)]\n",
      "The baby is crying because he/she is likely to be hungry.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "                                                                                                                                                                                                                                                                                                                                                                                                                                                             "
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
